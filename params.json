{
  "name": "HDB-on-HDP",
  "tagline": "Pivotal HDB on Hortonworks HDP Sandbox",
  "body": "# Pivotal HDB on Hortonworks HDP Sandbox\r\n\r\n<img src=\"https://raw.githubusercontent.com/dbbaskette/hdb-on-hdp/gh-pages/images/hdb.jpeg?token=ACbVkUI1WnnUpyJAOIAZbDH4AHJsBj63ks5WM91-wA%3D%3D\" width=\"300\">\r\n\r\n#### Packer-Based Build Process for adding Pivotal HDB to the Hortonworks HDP Sandbox\r\n\r\n**Requirements:**  \r\n\r\n* Packer  \r\n* VMware Fusion\r\n* Hortonworks HDP Sandbox 2.4\r\n* Pivotal HDB Package\r\n* Pivotal HDB Ambari Plugin Package\r\n* Apache MADlib for HDB Package\r\n\r\nThis release only works for the vmware version.\r\n\r\n* Download the VMWARE version of Sandbox 2.4 in to the main hdp-on-hpd directory. Leave it in its native downloaded format.\r\n* Place Pivotal HDB and Ambari Plugin packages in ./bins Directory. Leave them in their native *.tar.gz format.\r\n* Place MADlib Package in ./plugins.   Leave in Native *.tar.gz format\r\n* In build.sh, verify the value for the following variable: SANDBOX_BASENAME,OVFTOOL_BIN,VMRUN_BIN.   If needed, change them to the appropriate values, so that the first process of the builder will run properly.\r\n* Run ./build.sh vmware   (it's completely hands-off from here)\r\n* Output will be a Zip file containing the VM.    Move and unzip where you want to store the VM.  It does not require an import to work.\r\n\r\n\r\nBuild Process: (Steps that are performed)\r\n* If required, OVA will be converted to vmx format\r\n* VM is booted, Root password is changed, and then VM is shutdown.\r\n* VM is cloned.\r\n* HDB Repos are configured and plugin is installed\r\n* hdfs-site, core-site, and yarn-site are configured with appropriate values via Ambari API and then services are restarted.\r\n* HDB and PXF are installed via API and parameters are set.\r\n* HDB and PXF are started to complete installation\r\n* Apache MADlib is installed.\r\n* Tutorial GIT is cloned\r\n* Data files are moved into HDFS and a table is created in Hive\r\n* VM is cleaned up prior to shutdown\r\n* VM is shutdown and then compressed to a zip file.\r\n\r\n\r\nThis release will automatically download the HDB Tutorials (which are not completed).   This process also will load data into Hive for immediate query by PXF\r\n\r\n* Boot up the VM\r\n* login to Ambari at <ip>:8080 with admin/admin\r\n* start HDB and PXF\r\n* login to the command line as gpadmin (gpadmin/gpadmin)\r\n* Type:  psql -d template\r\n* from the psql shell type: select * from hcatalog.faa.otp limit 10;\r\n\r\nThis will directly query the Hive table leveraging the metadata from HCATALOG\r\n\r\n\r\n\r\nlogins:\r\n\r\nVM:\r\nroot/hawq2016\r\ngpadmin/gpadmin\r\nAmbari:\r\nadmin/admin\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}